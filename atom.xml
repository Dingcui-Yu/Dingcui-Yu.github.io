<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dingcui Yu&#39;s Homepage</title>
  
  
  <link href="http://dingcuiyu.github.io/atom.xml" rel="self"/>
  
  <link href="http://dingcuiyu.github.io/"/>
  <updated>2023-09-19T13:56:01.540Z</updated>
  <id>http://dingcuiyu.github.io/</id>
  
  <author>
    <name>Dingcui Yu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>利用io_uring实现高性能IO</title>
    <link href="http://dingcuiyu.github.io/2023/09/19/%E5%88%A9%E7%94%A8io-uring%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDIO/"/>
    <id>http://dingcuiyu.github.io/2023/09/19/%E5%88%A9%E7%94%A8io-uring%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BDIO/</id>
    <published>2023-09-19T12:34:00.000Z</published>
    <updated>2023-09-19T13:56:01.540Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://kernel.dk/io_uring.pdf">Efficient IO with io_uring</a></p><p>本文为该英文文档的翻译，此外还有一些个人理解。以下为正文：</p><p>本文为对最新的Linux IO接口 <code>io_uring</code> 的简介，并将其与现有IO接口进行比较。具体来说，我们将探讨 <code>io_uring</code> 被提出的原因、内部实现方式和用户态接口。本文并不会深入具体命令的细节，因为这些内容可以通过查阅man pages得到（但是不可避免地，会有一些重叠）。相反，本文的目的是介绍 <code>io_uring</code> 和它的工作方式，以使读者深入理解它的各个部分是如何组合到一起的。</p><h1>1.0 介绍</h1><p>Linux中有许多进行进行文件IO访问的接口。最古老、最基础的为 <code>read()</code> 和 <code>write()</code> 系统调用。后续还有 <code>pread</code> 和 <code>pwrite()</code>、  <code>preadv()</code> 和 <code>pwritev()</code> 、 <code>preadv2()</code> 和 <code>pwritev2()</code>等改进后的接口。它们均为同步接口，即这些系统调用在读或者写完成后才返回。在高并发场景下，同步接口的IOPS受限。 类似<code>aio_read()</code> 和 <code>aio_write()</code> 的异步接口被提出。然而，这些接口的实现不够优雅，性能也不太好。</p><p>具体来说，Linux原生的异步接口 <code>aio</code> 的缺点为：</p><ol><li>仅支持 <code>O_DIRECT</code> 模式（即绕过page cache）。</li><li>IO的提交依然可能被阻塞。例如，若IO提交需要等待元数据IO执行完成。又如，当存储设备的请求提交队列不可用时，IO的提交也会被阻塞。</li><li>需要额外的数据拷贝。每次IO请求提交需要拷贝64+8个字节，每次IO请求完成需要拷贝32个字节。</li></ol><p><em>由于时间关系，中间部分暂时略过，之后直接进行到 <code>io_uring</code> 的细节</em></p><h1>4.0 深入io_uring</h1><p><code>io_uring</code> 最开始的设计目标就是高效。我们不希望在IO提交和完成事务时有任何内存拷贝或是间接的内存访问。注意在 <code>aio</code> 的设计中，由于内核态与用户态的相互拷贝，性能和可扩展性都受到了影响。</p><p>为了达到这个目标，内核和用户必须优雅的共享由IO自己定义的数据结构。你可以想到，用户和内核共享数据结构必须需要某种同步机制。用户必须通过系统调用才能和内核共享锁，而系统调用会降低和内核通信的速率，影响性能。所以，我们选择使用生产商-消费者结构的环形缓冲区，以此消除用户和内核的共享锁，转而使用内存的barrier等机制。</p><p>在异步IO接口中，最基本的事情有二：提交请求和请求完成。当提交请求时，应用是生产者，内核是消费者；完成请求时则反之。所以，我们需要一对环形缓冲区，分别为提交队列（SQ）和完成队列（CQ）。</p><h2 id="4-1-数据结构">4.1 数据结构</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://kernel.dk/io_uring.pdf&quot;&gt;Efficient IO with io_uring&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文为该英文文档的翻译，此外还有一些个人理解。以下为正文：&lt;/p&gt;
&lt;p&gt;本文为对最新的Linux IO接口 </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>FAST 16 - CFFS阅读笔记</title>
    <link href="http://dingcuiyu.github.io/2023/04/18/FAST-16-CFFS%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://dingcuiyu.github.io/2023/04/18/FAST-16-CFFS%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2023-04-18T11:25:00.000Z</published>
    <updated>2023-04-18T11:40:35.918Z</updated>
    
    <content type="html"><![CDATA[<p><strong>The Composite-file File System: Decoupling the One-to-One Mapping of Files and Metadata for Better Performance</strong></p><p><code>Author</code>: Shuanglong Zhang. et al</p><p><code>Conference or Journal</code>: FAST；TOS</p><p><code>Institute</code>: Google &amp; Florida State University</p><p><code>IsOpenSource</code>: No</p><p><code>Link</code>: <a href="https://www.usenix.org/system/files/conference/fast16/fast16-papers-zhang-shuanglong.pdf">https://www.usenix.org/system/files/conference/fast16/fast16-papers-zhang-shuanglong.pdf</a></p><p><code>Published Date</code>: February 22, 2016 → March 1, 2020</p><h2 id="摘要">摘要</h2><p>传统的文件系统优化是基于文件与其元数据一一对应的基础上进行的，而这种文件-元数据的绑定会限制一些优化。本文设计并且实现、评估了一种复合文件文件系统，即允许文件到元数据的多对一映射。同时本文评估了多种映射机制的实现方式。在web服务器和软件生产工作集中，实证分析表明，本文提出的方式相比ext4，有超过27%的性能提升。</p><h2 id="背景">背景</h2><p>文件与元数据的一对一映射会限制一些优化方案。例如，预取多个文件块时也需要预取对应文件的元数据——而这是预取的主要副作用。有研究表明，访问32个小文件的延迟比访问同样大小的大文件的延迟高50%。</p><p>因此，作者提出把多文件复合，公用同一个元数据，以减少对元数据的磁盘访问。</p><h2 id="动机">动机</h2><p>具体来说，除了上文提到的预取开销，作者提出CFFS（Composite-File File System）的其他动机如下：</p><ul><li><strong>频繁的小文件访问</strong></li></ul><p>作者内部的分析表明，超过80%的文件访问是针对小于32KB的小文件的。在从磁盘读取小文件花费的时间中，接近40%的时间花在了元数据访问上。所以，减少元数据I/O访问开销很有效。</p><ul><li><strong>冗余的元数据信息</strong></li></ul><p>许多文件的元数据属性是一致的，例如文件持有者、访问权限等。有研究表明，在工作站中对元数据压缩有最多75%的压缩率。使用共用的元数据只能减少很少的空间占用，但可以减少很多对元数据的I/O访问。</p><ul><li><strong>文件成组访问</strong></li></ul><p>研究表明，文件大多数是一起被访问的。例如访问网页时会访问其中引用的文件页。但是，之前针对此的方法的性能提升并不是线性的，因为有文件聚集的开销。</p><ul><li><strong>访问每个文件的开销比较高</strong></li></ul><p>如下图，访问同样大小的数据，访问开销与文件大小成反比。同时印证了背景中提出的小文件开销过大的问题。</p><p><img src="https://s2.loli.net/2023/04/18/3EjP6g1IQ5DLVkS.png" alt="图 1"></p><h2 id="复合文件的文件系统（Composite-File-File-System-CFFS）设计">复合文件的文件系统（Composite-File File System, CFFS）设计</h2><p>**复合文件：**多个频繁被一起访问的小文件（<strong>子文件</strong>）组成复合文件，并共享一个元数据。小文件独有的元数据信息存储在 <code>inode</code> 中的 <code>extented attribute</code> 里。</p><p>复合文件对用户不可见，而且针对文件的各种语义（包括日志等）和操作的方式保持不变。</p><p>此时可以透明地利用VFS的预取以<strong>把多个小文件一起</strong>取到内存中。</p><h3 id="1、数据的表现形式">1、数据的表现形式</h3><p>子文件中的第一个文件是一个“entry point”，即开启预取的点。</p><h3 id="2、元数据的表现形式和对应操作">2、元数据的表现形式和对应操作</h3><ul><li><strong>复合文件创建</strong></li></ul><p>如下图：</p><p><img src="https://s2.loli.net/2023/04/18/m1oC7eRLSpuDEgc.png" alt="图 2"></p><ul><li><strong>权限</strong></li></ul><p>复合文件的 <code>inode</code> 的权限是所有子文件的权限的并集，每个子文件额外的权限会存储在附加属性中。</p><ul><li><strong>文件大小</strong></li></ul><p>当处于中间的子文件释放时，不会改变复合文件的大小。除非复合文件的空间利用率小于50%。</p><ul><li><code>inode</code> <strong>命名空间</strong></li></ul><p>复合文件的ID的高N位是复合文件的 <code>inode</code>  id，低M位用于子文件的ID。整个ID在本文中被称为 <code>CUID</code> 。如下图：</p><p><img src="https://s2.loli.net/2023/04/18/L621byYnsSxH5i3.png" alt="图 3"></p><ul><li><strong>重命名</strong></li></ul><p>如果不包括把一个普通文件转化为复合文件（或者相反的操作），则重命名不改变 <code>CUID</code> ，反之，重命名会改变 <code>CUID</code> 。</p><blockquote><p>这一设定对根据 <code>inode</code> 的“唯一性”、“不变性”来识别文件的应用不友好。</p></blockquote><ul><li><strong>锁</strong></li></ul><p>复合文件有一个锁，每个子文件同时各有一个锁。通常复合文件的锁可以同时获得，除非会影响到子文件之间的一致性（如更新子文件的成员、移动子文件在复合文件中的位置）。</p><ul><li><strong>更多</strong></li></ul><p>看论文。</p><h3 id="3、识别复合文件的成员">3、识别复合文件的成员</h3><ul><li><strong>基于目录的小文件复合</strong></li></ul><p>一个目录下的文件常常会被一起访问，所以这种办法把同一个目录下的文件（包括子目录）复合为一个复合文件。这种办法无法捕获目录间的文件关系。</p><ul><li><strong>基于内部引用的小文件复合</strong></li></ul><p><code>html</code> 文件中常常包含超链接，网络爬虫常常通过这些链接访问其他文件。</p><p>此外，基于 <code>Makefile</code> 的规则的编译也暗含了内部引用，即把生成同一个目标的源文件复合。</p><p>但问题是这种办法需要对文本格式有了解，进行特定格式的文本分析。</p><ul><li><strong>基于频率挖掘的小文件复合</strong></li></ul><p>可以使用Apriori算法来发掘频繁访问的模式。大致流程如下图：</p><p><img src="https://s2.loli.net/2023/04/18/6GaO4y1mwCfHPlW.png" alt="图 4"></p><p>详细原理请参考<a href="https://zhuanlan.zhihu.com/p/341882260">这里</a>。这种办法的内存和训练开销都很大。</p><h2 id="CFFS的实现">CFFS的实现</h2><p>本文使用 <code>FUSE(v2.9.3)</code>框架，在用户态建立了CFFS的原型，Linux版本是 <code>3.16.7</code> ，如下图：</p><p><img src="https://s2.loli.net/2023/04/18/7vXFlsdwStp2bOB.png" alt="图 5"></p><p>更多内容请见论文。</p><h2 id="实验">实验</h2><h3 id="实验环境">实验环境</h3><p><img src="https://s2.loli.net/2023/04/18/EefwFDckrZ81x5G.png" alt="图 6"></p><h3 id="实验结果">实验结果</h3><h4 id="Microbenchmark的实验结果">Microbenchmark的实验结果</h4><p>比较：完成时间</p><p><img src="https://s2.loli.net/2023/04/18/sXzo8jAhgU6MDZS.png" alt="图 7"></p><p><img src="https://s2.loli.net/2023/04/18/iaNl7HcojKwOvB2.png" alt="图 8"></p><h4 id="Web-Server-Trace-Replay的实验结果">Web Server Trace Replay的实验结果</h4><p>HDD 中1e-02之前的请求是缓存命中的。</p><p><img src="https://s2.loli.net/2023/04/18/4kfLxqcpB25Dr98.png" alt="图 9"></p><p><img src="https://s2.loli.net/2023/04/18/VG3UfMsT4lZFjR1.png" alt="图 10"></p><h4 id="Software-Development-File-System-Trace-Replay的实验结果">Software Development File System Trace Replay的实验结果</h4><p>因为不好收集单个请求的延迟，所以这里绘出了整体的完成时间。</p><p><img src="https://s2.loli.net/2023/04/18/gBJqbT1XvALamK2.png" alt="图 11"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;The Composite-file File System: Decoupling the One-to-One Mapping of Files and Metadata for Better Performance&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;c</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://dingcuiyu.github.io/categories/Paper-Reading/"/>
    
    
    <category term="FAST 16" scheme="http://dingcuiyu.github.io/tags/FAST-16/"/>
    
    <category term="TOS 20" scheme="http://dingcuiyu.github.io/tags/TOS-20/"/>
    
    <category term="Small Files" scheme="http://dingcuiyu.github.io/tags/Small-Files/"/>
    
    <category term="Metadata" scheme="http://dingcuiyu.github.io/tags/Metadata/"/>
    
    <category term="AI for Storage" scheme="http://dingcuiyu.github.io/tags/AI-for-Storage/"/>
    
    <category term="Prefetching" scheme="http://dingcuiyu.github.io/tags/Prefetching/"/>
    
  </entry>
  
  <entry>
    <title>Belady&#39;s MIN缓存管理算法阅读笔记</title>
    <link href="http://dingcuiyu.github.io/2023/04/09/Belady-s-MIN%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86%E7%AE%97%E6%B3%95%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://dingcuiyu.github.io/2023/04/09/Belady-s-MIN%E7%BC%93%E5%AD%98%E7%AE%A1%E7%90%86%E7%AE%97%E6%B3%95%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2023-04-09T09:01:00.000Z</published>
    <updated>2023-04-09T09:07:08.842Z</updated>
    
    <content type="html"><![CDATA[<h1>A study of replacement algorithms for a virtual-storage computer</h1><p>作者：L. A. Belady</p><p>期刊：IBM Systems Journal</p><p>年份：1966</p><p>原文不太好找，所以这里放一个<a href="https://github.com/detaos/thesis/blob/master/papers/A%20study%20of%20replacement%20algorithms%20for%20virtual%20storage%20computers.pdf">github网址</a>，里面可以下载。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;A study of replacement algorithms for a virtual-storage computer&lt;/h1&gt;
&lt;p&gt;作者：L. A. Belady&lt;/p&gt;
&lt;p&gt;期刊：IBM Systems Journal&lt;/p&gt;
&lt;p&gt;年份：1966&lt;/p</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://dingcuiyu.github.io/categories/Paper-Reading/"/>
    
    
    <category term="Cache Management" scheme="http://dingcuiyu.github.io/tags/Cache-Management/"/>
    
    <category term="Cache Eviction" scheme="http://dingcuiyu.github.io/tags/Cache-Eviction/"/>
    
    <category term="Classical" scheme="http://dingcuiyu.github.io/tags/Classical/"/>
    
  </entry>
  
  <entry>
    <title>FAST 23-OSML 阅读笔记</title>
    <link href="http://dingcuiyu.github.io/2023/03/31/Intelligent-Resource-Scheduling-for-Co-located-Latency-critical-Services-A-Multi-Model-Collaborative-Learning-Approach%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://dingcuiyu.github.io/2023/03/31/Intelligent-Resource-Scheduling-for-Co-located-Latency-critical-Services-A-Multi-Model-Collaborative-Learning-Approach%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2023-03-31T11:24:00.000Z</published>
    <updated>2023-03-31T12:32:42.465Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Intelligent Resource Scheduling for Co-located Latency-critical Services: A Multi-Model Collaborative Learning Approach</strong></p><p>作者：Lei Liu, Xinglei Dou, Yuetao Chen<br>会议：FAST<br>年份：2023</p><p>为了性价比的考虑，多种延迟敏感负载共同使用服务器。资源调度成为保证QoS的核心。但是，随着服务器资源的增多，资源调度越来越复杂，传统的调度器难以迅速高效地提供最优的策略。而且，” 资源峭壁”的存在也使得QoS存在抖动。为了解决这一问题，作者提出了OSML——基于机器学习的智能调度器。OSML主要学习硬件hint（如IPC、cache miss率、内存足迹等）、调度解决方案和QoS需求之间的关系，能预测QoS的变化、指导调度并且从违反QoS要求的情况下恢复回来。通过实验验证，OSML支持更高的负载、用更低的调度小号满足QoS需求，且和之前的调度器相比，缩短了收敛的时间。</p><p>开源网址（将在2023年八月公开）</p><p><a href="https://github.com/Sys-Inventor-Lab/AI4System-OSML">https://github.com/Sys-Inventor-Lab/AI4System-OSML</a></p><h2 id="背景">背景</h2><p>云应用由许多延迟敏感（Latency Critical, aka LC）服务组成，例如KV存储、数据库查询等，如下表。LC服务需要满足严格的QoS要求。</p><p><img src="https://s2.loli.net/2023/03/31/FDfn2rJR4lLyW3I.png" alt=" "></p><p>一方面，为了提高性价比，云服务提供商往往会在一个服务器上部署尽量多的应用。然而，这些应用，或者说组成它们的各类服务，在不同时间段，和各种层级的资源的交互模式多种多样，如CPU核、缓存、内存I/O带宽、内存bank等。同时，随着CPU核数增多，线程间对LLC（last-level cache）和内存带宽的竞争愈加激烈。甚至资源之间也存在交互。另一方面，随着硬件技术的发展，可调度的资源相比十年有了巨大提升，如Table 2，调度的“域”变大。<strong>在这一场景下对LC服务的资源调度非常复杂且耗时，这一现状对以QoS为导向的资源调度器的设计提出了不小的挑战。</strong></p><h2 id="现有工作">现有工作</h2><p>有些工作使用聚类算法把LLC和内存带宽分配给核，其中每个核调度单个线程。这种办法不适合云应用场景，因为这个场景下一般同时运行多个线程且每个线程都有严格的QoS要求。</p><p>其他工作要么使用启发式的思路——即某个时刻减少/增加某类资源，随后观察性能的变化，要么以相对直接的方式借助机器学习算法（如贝叶斯优化）进行资源调度。研究表明，用这些办法调度5个一起运行的LC服务，并且使它们都满足QoS需求需要花费20s（也就是说需要花20s来决策？）。</p><p>现有工作还可以在<strong>调度收敛时间</strong>、<strong>智能性</strong>和<strong>规定时间内完成复杂的交互式资源调度</strong>上有提升空间。以及还有一个重要的问题：<strong>它们能在多个LC服务同时部署在现代服务器上时，提供最优的资源调度策略吗？</strong></p><h2 id="动机">动机</h2><p>为了回答上述问题，作者分析了LC服务（如Table 1）的特征。实验环境如下Table 2左列所示。</p><p><img src="https://s2.loli.net/2023/03/31/BiFt1hqPLAHmdcl.png" alt=" "></p><h3 id="资源峭壁（RCliff）与最佳分配区域（OAA">资源峭壁（RCliff）与最佳分配区域（OAA)</h3><p>分析表明，<strong>LC服务对关键资源非常敏感，即使只少分配一点，也会造成巨大的QoS下滑</strong>。作者把这一现象称为“<strong>资源峭壁（Resource Cliff, aka RCliff</strong>）“。</p><p>这里所说的“关键资源”是如CPU核这类计算资源和如LLC ways这类存储资源。</p><p>作者测试了Table 1中列出的benchmark，每次实验均使用36个线程，以其中的Moses为代表，实验结果如下图：（方格内的数字表示响应延迟）</p><p><img src="https://s2.loli.net/2023/03/31/RjV6vEltBecwXra.png" alt="图 1"></p><p>当Core数目为6时，即使只减少1个LLC Way（从10减为9），响应延迟从34ms急速增长到4644ms。LLC Way固定，减少Core数也有类似的现象。作者把存在这一现象的区域用红框框起来了，如上图所示。</p><ul><li>造成Cache Cliff的原因是局部性。</li><li>造成Core Cliff的原因在于排队理论：当请求到达速率超过核数以及核的处理速率时，延迟会急速增长。</li></ul><p>调度器应该避免分配分配的资源落在资源峭壁边缘。</p><p>因此，作者划出了<strong>最佳分配区域（Optimal Allocation Area, aka OAA）</strong>，如上图黄框内区域，即满足QoS要求，又不至于分配过多资源。</p><p>不同的benchmark下能划出不同的RCliff区和OAA。</p><p>由于在实践中常常多个线程并发执行，所以引出下一个问题，<strong>OAA会随着线程数变化而变化吗？</strong></p><h3 id="OAA与线程数的关系">OAA与线程数的关系</h3><p>依然以Moses为例，如下图，不论线程数是20、28还是36，最佳的core都在8~10之间，说明<strong>OAA对线程数的变化不敏感。</strong></p><p><img src="https://s2.loli.net/2023/03/31/31N8hBoW2mitYFT.png" alt="图 2"></p><h3 id="现有的调度器可能遇到的问题">现有的调度器可能遇到的问题</h3><ol><li><strong>容易在RCliff周围徘徊</strong></li></ol><p>现有的启发式调度器根据观察到的性能变化增多/减少分配的资源，一方面，若给某应用分配的资源在RCliff之前（即图1中的黄色区域），由于它们对OAA没有概念，所以只能一步步细粒度地调整分配的资源；另一方面，若给某应用分配的资源在RCliff区内，则一点点资源的减少都会造成性能突然下降。</p><ol><li><strong>没法同时调度多种交互资源（如core、LCC way）以迅速到达OAA</strong></li></ol><p>启发式算法往往只调度一种资源。当需要调度多种资源时，往往需要花费较长时间才能达到OAA。</p><ol><li><strong>没法准确预测整体的QoS</strong></li></ol><p>要么违背QoS要求，要么分配过多预留资源。</p><p>总之，新的调度器的开发迫在眉睫。使用机器学习可以以较低的开销在复杂的情况下完全调度。</p><h2 id="OSML：利用机器学习进行调度">OSML：利用机器学习进行调度</h2><p>作者把调度的过程分为三个routine，并分别使用不同的机器学习模型：</p><p>1）Model A和Model B是静态的机器学习模型，分别负责预测OAA/RCliff和在多LC服务同时进行时，平衡QoS和所分配的资源；</p><p>2）Model C是强化学习模型，负责动态指导资源分配。</p><h3 id="Overview">Overview</h3><p><img src="https://s2.loli.net/2023/03/31/xsUPy1cph4XlBzj.png" alt="OSML Overview"></p><h3 id="Central-Logic">Central Logic</h3><p><img src="https://s2.loli.net/2023/03/31/Vyb2qfoRLGzYNvn.png" alt="OSML Central Logic"></p><h2 id="实验">实验</h2><ul><li>评测指标</li></ul><p>QoS：99th延迟</p><p>EMU：即Effiective Machine Utilization，代表所有共同运行的LC服务的最大负载</p><ul><li>对比的方案<ul><li>PARTIES：一个启发式调度策略</li><li>CLITE：一个基于贝叶斯优化的调度策略</li><li>Unmanaged Allocation：不调度，代表下限</li><li>ORACLE：离线学习了大量数据并且找到了最好的方案，代表上限</li></ul></li></ul><h3 id="实验结果">实验结果</h3><ul><li>由于Model A提供的出发点更接近OAA，所以OSML能用更短的收敛时间实现同样的EMU</li></ul><p><img src="https://s2.loli.net/2023/03/31/NAW4D2ZuCbealpv.png" alt="图(a)中每个点表示1个load，三种策略分别测试了104个load，均收敛。图(b)是图(a)中load的收敛时间的Violin Plots"></p><ul><li>同样的Load，OSML可以使用更少的资源使它们达到QoS要求</li></ul><p><img src="https://s2.loli.net/2023/03/31/q7lmxEivTLMosR3.png" alt="均使用Moses、Img-dnn和Xapian的40%、60%和50%组成的load"></p><ul><li>由于OSML支持资源共享，所以能支持更多load</li></ul><p><img src="https://s2.loli.net/2023/03/31/9IJgwKSPkDtbiQu.png" alt="使用Moses、Img-dnn和Xapian组成的load，横轴和纵轴分别表示使用它们各自的x%的负载，而方格中的数字表示支持的Xapian的最大x%的负载，红叉表示不支持（即无法达到QoS要求）"></p><ul><li>由于Model C的动态调整，在新服务到来/旧load发生变化时，OSML能更快调整</li></ul><p><img src="https://s2.loli.net/2023/03/31/mtqRnAcPN2epFDU.png" alt="16~80s时，新服务到来，OSML在Point 48就能提供更好的解决方案；180~228s时，Img-dnn改变了load，OSML能很快满足需求的变化"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Intelligent Resource Scheduling for Co-located Latency-critical Services: A Multi-Model Collaborative Learning Approach&lt;/strong&gt;&lt;</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://dingcuiyu.github.io/categories/Paper-Reading/"/>
    
    
    <category term="AI for Storage" scheme="http://dingcuiyu.github.io/tags/AI-for-Storage/"/>
    
    <category term="FAST 23" scheme="http://dingcuiyu.github.io/tags/FAST-23/"/>
    
    <category term="Resource Scheduling" scheme="http://dingcuiyu.github.io/tags/Resource-Scheduling/"/>
    
  </entry>
  
  <entry>
    <title>ChCore-lab-v2-ECNUver: LAB 2 </title>
    <link href="http://dingcuiyu.github.io/2023/03/14/ChCore-lab-v2-ECNUver-LAB-2-%E4%B8%8A%EF%BC%89/"/>
    <id>http://dingcuiyu.github.io/2023/03/14/ChCore-lab-v2-ECNUver-LAB-2-%E4%B8%8A%EF%BC%89/</id>
    <published>2023-03-14T13:39:00.000Z</published>
    <updated>2023-03-31T12:39:41.623Z</updated>
    
    <content type="html"><![CDATA[<h1>实验2：内存管理</h1><p>本实验主要目的在于让同学们熟悉计算机进行地址翻译的过程，并且了解计算机启动过程中，如何对内存初始化，以及启动完成后对内存和页表的管理。</p><p>包括三个部分：内核启动页表、物理内存管理和页表管理。</p><p>注：为了帮助同学们了解这些知识，本节会出现少量“小思考”，不会算入实验报告评分。</p><h2 id="课堂回顾-地址翻译机制与多级页表">课堂回顾:地址翻译机制与多级页表</h2><p>本部分为地址翻译的介绍，若对这一部分有充分了解的同学可以放心跳过~（<strong>但不要跳过思考题</strong>）</p><h4 id="地址翻译的机制">地址翻译的机制</h4><p>内存的访问粒度是Byte（即每次最少读/写一个Byte），每个Byte有一个“编号”，这个“编号”就是地址。<strong>地址空间</strong> 就是可以访问的地址的集合。</p><p>C语言中的指针变量存储的就是数据的地址，我们可以通过<code>%p</code>在<code>printf</code>函数中输出它，例如下面的代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">int</span> n;</span><br><span class="line">        n=<span class="number">10</span>;</span><br><span class="line">        <span class="type">int</span>* ptr=&amp;n; <span class="comment">//ptr存放n的地址</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;n=%d\n&quot;</span>,n);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;&amp;n=%p\n&quot;</span>,ptr);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果（运行于x86-64平台、Linux操作系统）为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">misao@misao-virtual-machine:~$ ./test </span><br><span class="line">n=10</span><br><span class="line">&amp;n=0x7ffed8e6c5bc</span><br></pre></td></tr></table></figure><p>这个地址是 <strong>虚拟地址</strong> ，即应用“看到”，并且使用的地址。数据（如上面的代码中的<code>n</code>）在内存中实际存储的位置是 <strong>物理地址</strong> ，也即访问内存实际用的地址。</p><p>这就引出了两个值得思考的问题：</p><p><strong>问题一：既然需要使用物理地址访问内存，操作系统为什么不直接让应用使用物理地址呢？</strong></p><p>如果操作系统允许应用直接使用物理地址，那么会有两个棘手的问题：第一，难以保证不同应用之间的内存隔离。例如，应用A给变量<code>n</code>赋值10，另一应用B可能故意或者不小心把<code>n</code>改成其他值，进而导致A的运行出错；第二，难以保证一个应用的地址空间连续且统一，当一台机器同时运行多个应用时，它们共享同一块内存，应用难以判断自己可用的空间有多少，此时内存的布局会变得非常复杂。</p><p>这两个难题的原因就是没有一个”领导“协调多个应用对同一个内存的使用，因此，需要操作系统对内存进行统一管理。</p><p>为了实现这一点，需要对物理内存 <strong>虚拟化</strong> ，即令每个应用都认为自己可以使用整块连续的内存，所以说应用使用的地址是虚拟地址，在实际访问时再根据操作系统指定的地址翻译规则进行地址翻译，把虚拟地址翻译为物理地址。</p><p><strong>问题二：虚拟地址到物理地址的转化（翻译）是如何执行的？</strong></p><p>虚拟地址的转化（翻译）是由CPU（硬件）配合操作系统（软件）完成的。一方面，CPU根据地址翻译规则，把虚拟地址转化为物理地址，然后通过总线进行内存读写操作；另一方面，操作系统为每个应用配置地址翻译规则，但不参与具体的翻译过程。</p><p>具体来说，CPU中的重要部件—— <strong>内存管理单元（Memory Management Unit, MMU）</strong> 负责虚拟地址到物理地址的转换。即，应用在CPU上运行时，它使用的虚拟地址由MMU转化为物理地址。当需要访问内存时，MMU翻译得到的物理地址通过总线传到物理内存，从而完成物理内存的读写。</p><blockquote><p>地址翻译体现了”策略与机制分离“的设计思路：操作系统仅仅负责配置地址翻译规则（策略），地址翻译则由CPU完成（机制），二者通过一个特定的数据结构（页表，功能是记录地址翻译规则）实现协同。我们将在下一节介绍页表。</p></blockquote><h4 id="分页机制和页表">分页机制和页表</h4><p>分页机制的基本思想是把应用的虚拟地址空间划分为连续、等长的虚拟页，同时物理地址空间也被划分为连续、等长的物理页。</p><p>假设页大小为4KB，那么虚拟地址0x 0000~0x 1000（即0B~4KB）是虚拟页0，0x 1000~0x 2000（即4KB~8KB）是虚拟页1；类似地，物理地址0x 0000~ 0x1000是物理页0，0x 1000~0x 20000是物理页1。</p><blockquote><p>内存地址一般用十六进制数表示，0x 1000中前面的“0x”表示这是一个十六进制数字，对应的十进制数是4096，即4K。但是计算机读入的数都是二进制数。</p></blockquote><p>虚拟页和物理页大小固定且相等，因此操作系统可以轻松为应用构建一张记录虚拟页到物理页的映射关系表，即页表。</p><p>有了分页机制后，虚拟/物理地址就可以看作由两部分组成：第一部分标识对应的 <strong>页号</strong> ，第二部分标识 <strong>页内偏移</strong> 。假如页大小为4KB，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>K</mi><mo>=</mo><msup><mn>2</mn><mn>12</mn></msup></mrow><annotation encoding="application/x-tex">4K=2^{12}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span></span></span></span></span></span></span></span>，则页内偏移需要12位来表示。例如，虚拟地址0x 2008，标识了虚拟页号2和页内偏移0x 8。</p><blockquote><p>这里出现的“用12位来表示”指的是二进制数的前12位，后文中出现的“位数”也指二进制数的位数，例如0x 2008的二进制数为b 0010 0000 0000 1000，这个数字的后12位（0000 0000 1000)表示页内偏移，对应十六进制的后三位。</p></blockquote><p>寻址示意图如下：</p><p><img src="https://s2.loli.net/2023/03/14/VsjC6fUoKkLAgM3.png" alt="寻址示意图"></p><p>MMU拿到应用的虚拟地址（0x 2008）后，查询该应用的页表，得知物理页号是3，得出物理页的基地址为0x 3000，最后加上基地址0x 8得到物理地址0x 3008。</p><blockquote><p>小思考：根据上面的页表，虚拟地址0x1fca对应的物理地址是什么？</p></blockquote><p>这样，对应用来说，自己的地址空间就是连续的：应用只需要使用虚拟地址，不需要关心虚拟地址到物理地址的转换过程。而操作系统可以通过为不同应用建立不同的页表，如对应用A而言，虚拟页号0对应物理页号1，而对应用B而言，虚拟页号0对应物理页号4，从而实现不同应用的内存隔离。</p><p>最后，为了使MMU可以在内存中找到页表，需要把页表的起始地址放在特殊的寄存器中，这个寄存器就是<strong>页表基地址寄存器</strong>，在AArch64平台中，这个寄存器是TTBR（Translation Table Base Register）。</p><blockquote><p>小思考：TTBR中保存的“页表基地址”是物理地址，还是虚拟地址？</p></blockquote><h4 id="多级页表">多级页表</h4><p>上文中出现的页表为单级页表，大家可以计算一下，假如虚拟地址一共有48位，页大小为4K，那么一共有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><msup><mn>2</mn><mn>48</mn></msup><msup><mn>2</mn><mn>12</mn></msup></mfrac></mstyle><mo>=</mo><msup><mn>2</mn><mn>36</mn></msup></mrow><annotation encoding="application/x-tex">\cfrac{2^{48}}{2^{12}}=2^{36}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.276em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.74em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">48</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">36</span></span></span></span></span></span></span></span></span></span></span></span>个虚拟页。假如每个页表项大小为8 Byte，则页表大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>36</mn></msup><mo>×</mo><mn>8</mn><mi>B</mi><mo>=</mo><mn>512</mn><mi>G</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">2^{36}\times 8 B= 512 GB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">36</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">8</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">512</span><span class="mord mathnormal" style="margin-right:0.05017em;">GB</span></span></span></span>！而且，这张页表占据的物理内存必须连续！</p><p>所以，必须想办法压缩页表的大小。</p><p>与此同时，我们发现，<strong>大多数应用使用的虚拟地址远远小于总的虚拟地址空间</strong>，也即单级页表中的大部分表项根本没有被使用。</p><p>因此，在实际场景中，操作系统通常使用<strong>多级页表</strong>，如下图：</p><p><img src="https://s2.loli.net/2023/03/14/scrlBPY9NzWm1FX.png" alt="多级页表"></p><p>64位的虚拟地址实际使用于寻址的有48位，其中12到47位标识虚拟页号，0到11位标识页内偏移。虚拟页号被分为四级，每个级有9位。例如，MMU先读入虚拟地址<code>0x 0000 0000 2008</code>，通过TTBR读入L0页表的物理地址后，再根据39到47位获得L0页表的页表项0，然后读取L0页表中存储的L1物理页号，依次读到L3页表，获得其中存储的物理页号，最后根据页内偏移获得数据的物理地址。</p><blockquote><p>因为页大小为4KB，且每个页表项大小为8 Byte，所以每个页表有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><msup><mn>2</mn><mn>12</mn></msup><msup><mn>2</mn><mn>3</mn></msup></mfrac></mstyle><mo>=</mo><msup><mn>2</mn><mn>9</mn></msup><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">\cfrac{2^{12}}{2^3}=2^9=512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.276em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.74em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">9</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">512</span></span></span></span>项，为了索引512个页表项，需要9位，所以虚拟页号的每一级有9位。</p></blockquote><p>多级页表的好处就是，当任意一级页表中的某一个条目位空时，该条目对应的下一级页表不需要存在。换句话说，多级页表允许整个页表结构出现“空洞”，而单级页表则需要每一项都实际存在。</p><p>而在实际情况下，应用的虚拟地址空间中绝大多数虚拟地址不会被使用，所以多级页表通常具有许多“空洞”，从而能极大节约页表占用的空间。</p><h4 id="思考题-1">思考题 1</h4><blockquote><p>1995年，Intel在奔腾Pro处理器上推出PAE（Physical Address Extension）技术，支持36位物理地址（即最大64GB），但虚拟地址依然只有32位（即虚拟地址空间为32GB）。由于物理地址是36位，所以页表项大小为 64位（8 Byte），每个页表依然有512项，使用9位索引，因此使用2+9+9+12三级索引。请计算在用满4GB的虚拟地址空间的情况下，多级页表和单级页表分别占用多少空间？并且思考多级页表一定能减少单级页表占用的空间吗？</p></blockquote><h2 id="AArch64地址翻译">AArch64地址翻译</h2><p>MMU硬件在EL1特权级（操作系统运行的特权级）中提供了两个页表基地址寄存器，分别是<code>TTBR0_EL1</code>和<code>TTBR1_EL1</code>。当虚拟地址的48~63位全为0时，MMU硬件基于<code>TTBR0_EL1</code>寄存器存储的页表进行地址翻译；当虚拟地址的48~63位全为1时，MMU硬件基于<code>TTBR1_EL1</code>寄存器存储的页表进行地址翻译。</p><p>即0x 0000 0000 0000 ~ 0x 0000 ffff ffff的地址使用<code>TTBR0_EL1</code>寄存器，0x ffff 0000 0000~0x ffff ffff ffff 的地址使用<code>TTBR1_EL1</code>寄存器。</p><blockquote><p>Hint： ChCore中0x ffff ff00 0000 0000之后的为内核的高地址，不过这不影响我们理解</p></blockquote><h4 id="页表项">页表项</h4><p>页表项（Page Table Entry，简称PTE）一般存储表描述符或页描述符，除了下一级页表（或者物理页）的物理页号（Page Frame Number，简称PFN）外，还存储一些属性位。如下图，第0位为<code>is_valid</code>位，为1时表示这个页表项有效，第1位为<code>is_page</code>或者<code>is_table</code>位，为1时表示页表项中的PFN指向的是页表或者物理页。</p><p><img src="https://s2.loli.net/2023/03/14/Sdo8Pf794gKluWY.png" alt="页表项"></p><p>在ChCore中，页表项的定义在文件<code>kernel\include\arch\aarch64\arch\mm\page_table.h </code>内，</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义了一些宏</span></span><br><span class="line">…</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义各级页表项</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">                u64 is_valid : <span class="number">1</span>, <span class="comment">//是否有效</span></span><br><span class="line">                    is_table : <span class="number">1</span>, <span class="comment">//是否还有下一级</span></span><br><span class="line">                    ...</span><br><span class="line">                    next_table_addr : <span class="number">36</span>, <span class="comment">//下一级的物理地址</span></span><br><span class="line">                    ...</span><br><span class="line">        &#125; table;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">                u64 is_valid : <span class="number">1</span>,</span><br><span class="line">                    is_table : <span class="number">1</span>,</span><br><span class="line">                    ...</span><br><span class="line">                    pfn : <span class="number">18</span>,</span><br><span class="line">                    ...</span><br><span class="line">        &#125; l1_block;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">                u64 is_valid : <span class="number">1</span>,</span><br><span class="line">                    is_table : <span class="number">1</span>,</span><br><span class="line">                    ...</span><br><span class="line">                    pfn : <span class="number">27</span>,</span><br><span class="line">                    ...</span><br><span class="line">        &#125; l2_block;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">                u64 is_valid : <span class="number">1</span>,</span><br><span class="line">                    is_page : <span class="number">1</span>,</span><br><span class="line">                    ...</span><br><span class="line">                    pfn : <span class="number">36</span>,</span><br><span class="line">                    ...</span><br><span class="line">        &#125; l3_page;</span><br><span class="line">        u64 pte;</span><br><span class="line">&#125; <span class="type">pte_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义页表</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="type">pte_t</span> ent[PTP_ENTRIES];</span><br><span class="line">&#125;<span class="type">ptp_t</span>;</span><br></pre></td></tr></table></figure><h4 id="思考题-2">思考题 2</h4><blockquote><p>上图中还出现了其他属性位，如UXN、PXN、AF、AP，请你阅读ChCore中<code>kernel\include\arch\aarch64\arch\mm\page_table.h</code>中对<code>pte_t</code>的定义，并结合查阅到的其他资料，说明这四个属性位的作用。</p></blockquote><h2 id="PART-1：配置内核启动页表">PART 1：配置内核启动页表</h2><p>在LAB 1中，我们学到内核启动时，开启MMU之前，CPU访问内存使用物理地址，开启MMU之后使用虚拟地址。而在LAB 1的TODO 2里，我们在<strong>未配置启动页表</strong>时直接启动MMU，因此在这之后，CPU认为自己访问的是虚拟地址，会先查询页表，由于页表未配置，查表失败，因此发生地址翻译错误，执行流来到0x200处无限循环。</p><p>具体表现为，在QEMU窗口中只输出两行：</p><p><img src="https://s2.loli.net/2023/03/20/Od7nLzHF4cYZvfb.png" alt="LAB 1 QEMU窗口的输出"></p><p>而在gdb调试窗口中，刚好卡在开启MMU之后：</p><p><img src="https://s2.loli.net/2023/03/20/UkAVZC8Qt9R7Lyn.png" alt="LAB 1 gdb窗口"></p><p>ChCore使用位于<code>kernel\arch\aarch64\boot\raspi3\init\mmu.c</code>中的<code>init_boot_pt</code>函数初始化内核启动页表。在LAB 2中，我们已经配置好了低地址空间的映射表，因此在LAB 2的一开始，QEMU窗口会输出四行，</p><p><img src="https://s2.loli.net/2023/03/20/UgVjwzBaoM9fnlG.png" alt="LAB 2 QEMU窗口输出"></p><p>而通过gdb查询到，我们在<code>init_c</code>函数结束后要跳转到<code>start_kernel</code>函数，而这个函数的虚拟地址是高地址，因此无法顺利跳转：</p><p><img src="https://s2.loli.net/2023/03/20/FHGil92Jjyh86ad.png" alt="LAB 2 gdb窗口与对应源代码"></p><p>因此，在LAB 2里，我们的<strong>主线任务</strong>就是配置内核启动页表🙌</p><p>所谓的”配置页表“其实是一个很直接的事情，从上一节我们知道，一个”页表(<code>ptp_t</code>)“就是由页表项(<code>pte_t</code>)数组组成的，所以我们配置的时候就根据虚拟地址找到页表项，然后按照需要填写属性即可。</p><p>主要填写的属性有三个：</p><table><thead><tr><th>is_valid</th><th>1表示有效；0表示无效</th></tr></thead><tbody><tr><td>is_table or is_page</td><td>1表示有下一级页表或者物理页；0表示没有下一级页表</td></tr><tr><td>pfn or next_table_addr</td><td>表示下一级页表或者物理页的物理地址</td></tr></tbody></table><p>在低地址空间，内核页表的虚拟地址与物理地址一一对应，即虚拟地址A映射到物理地址A。</p><p>在高地址空间，内核页表的虚拟地址0x ffff ff00 0000 0000 +A映射到物理地址A。</p><blockquote><p>小思考：为什么建立内核启动页表时既要建立低地址空间的映射，又要建立高地址空间的映射？</p></blockquote><p>所以，我们现在只需要知道<strong>地址空间范围</strong>，就可以开始配置内核启动页表了，如下表：</p><table><thead><tr><th><strong>虚拟地址（高）</strong></th><th><strong>虚拟地址（低）</strong></th><th><strong>物理地址</strong></th><th><strong>对应设备</strong></th></tr></thead><tbody><tr><td>0xffff  ff00 0000 0000  ~  0xffff  ff00 3f00 0000</td><td>0x  0000 0000 0000 0000  ~  0x  0000 0000 3f00 0000</td><td>0x  0000 0000 0000 0000  ~  0x  0000 0000 3f00 0000</td><td>物理内存（SDRAM）  类型：NORMAL_MEMORY</td></tr><tr><td>0xffff  ff00 3f000 0000  ~  0xffff  ff00 4000 0000</td><td>0x  0000 0000 3f00 0000  ~  0x  0000 0000 4000 0000</td><td>0x  0000 0000 3f00 0000  ~  0x  0000 0000 4000 0000</td><td>共享外设内存  类型：  DEVICE_MEMORY</td></tr><tr><td>0xffff  ff00 4000 0000  ~  0xffff  ff00 8000 0000</td><td>-</td><td>0x  0000 0000 4000 0000  ~  0x  0000 0000 8000 0000</td><td>本地外设内存  类型：  DEVICE_MEMORY</td></tr></tbody></table><p>在ChCore的文件<code>kernel/arch/aarch64/boot/raspi3/init/mmu.c</code>中，我们已经以全局变量的方式定义了L0、L1、L2级页表各一个：</p><p><img src="https://s2.loli.net/2023/03/20/VOEcf5tuB3KP16D.png" alt="L0、L1、L2页表"></p><blockquote><p>小思考：为什么不定义L3页表？</p></blockquote><h4 id="练习-1">练习 1</h4><blockquote><p>请你在<code>init_boot_pt</code>函数的LAB 2 TODO 1中补全代码，仿照我们实现的内核低地址映射，完成内核高地址映射。</p><p>提示：</p><ul><li>内核代码的高地址空间开始位置存储在宏 <code>KERNEL_VADDR</code> 中。</li><li>练习完成后，可以在start_kernel函数处打断点，测试能否成功通过高地址访问内存。</li></ul></blockquote><h2 id="PART-2：物理内存管理">PART 2：物理内存管理</h2><p>上一部分我们成功配好了内核启动页表，此时ChCore可以顺利跳转到start_kernel，随后跳转到main函数，完成内核启动（boot）ヽ(✿ﾟ▽ﾟ)ノ</p><p><img src="https://s2.loli.net/2023/03/20/SoibrkILd9n78Uc.png" alt="PART 1成功后的gdb调试结果"></p><p>但是，为了快速启动内核，我们使用的所有页表页的地址都是<strong>静态</strong>分配的！</p><p>在理论课的学习中，我们想象中的页表配置应该是<strong>动态</strong>分配的：</p><p><img src="https://s2.loli.net/2023/03/20/rAsTKno2W8vVFNX.png" alt="动态分配页表地址"></p><p>因此，PART 2里我们将实现一个动态内存分配器。</p><p>作为OS领域经久不衰的研究课题，动态内存分配器干的最重要的三件事是：管理所有空闲页、分配空闲页和释放已分配的空闲页。</p><p>ChCore里使用<code>struct page</code>管理物理页，使用<code>struct phys_mem_pool</code>管理一组物理页。其中，在<code>struct phys_mem_pool</code>中定义了<strong>空闲链表</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kernel/include/mm/buddy.h</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">phys_mem_pool</span>&#123;</span></span><br><span class="line">    u64 pool_start_addr;</span><br><span class="line">    u64 pool_mem_size;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">page_metadata</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">free_list</span> <span class="title">free_lists</span>[<span class="title">BUDDY_MAX_ORDER</span>];</span> <span class="comment">//空闲链表</span></span><br><span class="line">&#125;;</span><br><span class="line">…</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">free_list</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">free_list</span>;</span></span><br><span class="line">        u64 nr_free;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>接下来，我们在需要空闲页时从空闲链表中剔除页，而在释放空闲页时把释放出的页添加到空闲链表。</p><p>具体来说，ChCore使用<strong>伙伴系统</strong>管理动态内存：</p><p><img src="https://s2.loli.net/2023/03/20/cXTmj6tqysYdIGZ.png" alt="伙伴系统示意图（图源网络）"></p><p>开始时所有页组成一个连续的空间，当有内存分配请求时，这个空间会一份为二，这个分割出来的两份就是”伙伴“，其中一个伙伴还是空闲状态，另一个伙伴则继续分裂，直到获得请求需要的物理内存大小。</p><p>例如，我们需要分配15K的物理内存，我们需要和2的幂次对齐，所以选择向伙伴系统请求16K的空闲内存空间。但目前链表数组中没有16K的空闲空间，因此向上查询更大的空间空间，发现有32K的内存（斜线部分），对其拆分，拆分后得到两16K空闲内存，其中一块插入空闲链表，另一块的物理地址则发送给应用。</p><p><img src="https://s2.loli.net/2023/03/20/89rlRyeES6bNFzH.png" alt="分配15K的内存示意图（图源网络）"></p><h4 id="练习-2">练习 2</h4><blockquote><p>完成<code>kernel/mm/buddy.c</code>中的<code>split_page</code>、<code>buddy_get_pages</code>、<code>merge_page</code>和<code>buddy_free_pages</code>函数中的LAB2 TODO2部分。</p><p>其中，<code>buddy_get_pages</code>用于分配指定阶大小的连续物理页，<code>buddy_free_page</code>s用于释放已分配的连续物理页。</p><p>提示：</p><ul><li>可以使用 <code>kernel/include/common/list.h</code> 中提供的链表相关函数如 <code>init_list_head</code>、<code>list_add</code>、<code>list_del</code>、<code>list_entry</code> 来对伙伴系统中的空闲链表进行操作。</li><li>可使用 <code>get_buddy_chunk</code> 函数获得某个物理内存块的伙伴块。</li><li>更多提示见代码注释。</li></ul></blockquote><h2 id="PART-3：页表管理">PART 3：页表管理</h2><p>现在，我们可以使用动态内存分配来配置页表了！</p><h4 id="练习-3">练习 3</h4><blockquote><p>完成<code>kernel/arch/aarch64/mm/page_table.c</code> 中的<code> query_in_pgtbl</code>、<code>map_range_in_pgtbl</code>、<code>unmap_range_in_pgtbl</code> 函数中的 LAB 2 TODO 3 部分，分别实现页表查询、映射、取消映射操作。</p><p>提示：</p><ul><li>实现中可以使用 <code>get_next_ptp</code>、<code>set_pte_flags</code>、<code>GET_LX_INDEX</code> 等已经给定的函数和宏。</li><li>更多提示见代码注释。</li></ul></blockquote><h4 id="思考题（选做）">思考题（选做）</h4><blockquote><p>课堂上我们提到内存页大小为4KB，使用了L0、L1、L2、L3四级页表。其实Linux还实现了“大页”，其大小有2MB、1GB等。</p><p>请你查阅相关资料，描述2MB和1GB的页表结构以及对应的虚拟地址的各个位的划分，并描述大页相比4KB页的优缺点。</p></blockquote><h4 id="思考题（选做）-2">思考题（选做）</h4><blockquote><p>请你查阅相关资料，调研slab分配器，并说明它与伙伴系统的不同之处，以及Linux中它们是如何共同管理内存空间的。</p></blockquote><h4 id="思考题（选做）-3">思考题（选做）</h4><blockquote><p>在ChCore中，我们对内核启动页表初始化时，L0、L1和L2级页表页已经静态地分配好了，所以我们能直接对内核启动页表初始化。</p><p>请你查阅资料，结合代码，描述Linux 2.6是如何初始化内核启动页表的？</p><p>提示：可以阅读《深入理解Linux内核》第三版第74页到78页的内容，这里描述了Linux 2.6的内核启动页表初始化过程。</p></blockquote><h4 id="挑战题（选做）">挑战题（选做）</h4><blockquote><p>使用前面实现的 page_table.c 中的函数，在内核启动后重新配置内核页表，进行细粒度的映射。</p></blockquote><h2 id="小思考的答案">小思考的答案</h2><ol><li>0x0fcs</li><li>物理地址</li><li>因为内核启动时需要在低地址运行一段时间，随后才跳转到高地址。</li><li>有三点原因：其一，内核启动时不存在其他应用的干扰，因此可以直接建立一大块内存的映射；其二，为了快速配好内核启动页表，完成启动；其三，此时还没实现动态内存分配器，无法动态分配页表页。需要建立映射的地址空间跨度为2G，需要大量L3页表，而只需要L0、L1和L2页表各一个。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;实验2：内存管理&lt;/h1&gt;
&lt;p&gt;本实验主要目的在于让同学们熟悉计算机进行地址翻译的过程，并且了解计算机启动过程中，如何对内存初始化，以及启动完成后对内存和页表的管理。&lt;/p&gt;
&lt;p&gt;包括三个部分：内核启动页表、物理内存管理和页表管理。&lt;/p&gt;
&lt;p&gt;注：为了帮助同学们了</summary>
      
    
    
    
    <category term="OSLab" scheme="http://dingcuiyu.github.io/categories/OSLab/"/>
    
    
    <category term="实验手册" scheme="http://dingcuiyu.github.io/tags/%E5%AE%9E%E9%AA%8C%E6%89%8B%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://dingcuiyu.github.io/2023/03/14/test/"/>
    <id>http://dingcuiyu.github.io/2023/03/14/test/</id>
    <published>2023-03-14T09:06:45.000Z</published>
    <updated>2023-03-14T14:21:01.379Z</updated>
    
    <content type="html"><![CDATA[<h1>test</h1><p>This is a test file.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;test&lt;/h1&gt;
&lt;p&gt;This is a test file.&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
</feed>
